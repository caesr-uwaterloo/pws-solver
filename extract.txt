0: s_load_dword
8: s_mov_b32
12: s_lshl_b64
16: v_or_b32
20: s_waitcnt
24: v_cmp_le_i32
32: v_cmp_gt_i32
36: s_and_saveexec_b64
40: s_cbranch_execz
44: s_load_dwordx8
52: v_ashrrev_i32
56: s_waitcnt
60: v_mov_b32
64: v_add_u32
68: v_addc_u32
72: flat_load_ubyte
80: s_waitcnt
84: v_cmp_ne_u16
88: s_mov_b64
92: s_and_saveexec_b64
96: s_cbranch_execz
100: v_mov_b32
104: flat_store_byte
112: v_lshlrev_b64
120: v_mov_b32
124: v_add_u32
128: v_addc_u32
132: flat_load_dword
140: v_mov_b32
144: s_waitcnt
148: v_ashrrev_i32
152: v_lshlrev_b64
160: v_add_u32
164: v_addc_u32
168: flat_load_dword
176: s_load_dwordx4
184: s_waitcnt
188: v_mov_b32
192: s_waitcnt
196: v_ashrrev_i32
200: v_add_u32
204: v_addc_u32
208: flat_load_ubyte
216: s_waitcnt
220: v_cmp_ne_u16
224: s_and_saveexec_b64
228: s_xor_b64
232: s_cbranch_execz
236: s_nop
240: s_or_saveexec_b64
244: s_xor_b64
248: s_cbranch_execz
252: v_lshlrev_b64
260: v_mov_b32
264: v_add_u32
268: v_addc_u32
272: flat_load_dword
280: v_lshlrev_b64
288: v_mov_b32
292: v_mov_b32
296: v_mov_b32
300: v_add_u32
304: v_addc_u32
308: v_add_u32
312: v_addc_u32
316: s_waitcnt
320: v_add_u32
324: flat_store_dword
332: flat_store_byte
340: s_or_b64
344: s_xor_b64
348: s_or_b64
352: s_andn2_b64
356: s_and_b64
360: s_or_b64
364: s_or_b64
368: s_and_saveexec_b64
372: s_cbranch_execz
376: s_nop
380: s_endpgm
512: s_load_dword
520: s_mov_b32
524: s_lshl_b64
528: v_or_b32
532: s_waitcnt
536: v_cmp_gt_i32
540: s_and_saveexec_b64
544: s_cbranch_execz
548: s_load_dwordx8
556: v_ashrrev_i32
560: s_waitcnt
564: v_mov_b32
568: v_add_u32
572: v_addc_u32
576: flat_load_ubyte
584: s_waitcnt
588: v_cmp_ne_u16
592: s_and_b64
596: s_cbranch_execz
600: v_mov_b32
604: v_mov_b32
608: v_mov_b32
612: v_add_u32
616: v_addc_u32
620: v_mov_b32
624: v_add_u32
628: v_addc_u32
632: v_mov_b32
636: flat_store_byte
644: flat_store_byte
652: flat_store_byte
660: v_mov_b32
664: flat_store_byte
672: s_endpgm
