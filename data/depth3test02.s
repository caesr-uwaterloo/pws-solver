	.text
	.amdgcn_target "amdgcn-amd-amdhsa--gfx801+xnack"
	.protected	_Z9syntheticm           ; -- Begin function _Z9syntheticm
	.globl	_Z9syntheticm
	.p2align	8
	.type	_Z9syntheticm,@function
_Z9syntheticm:                          ; @_Z9syntheticm
_Z9syntheticm$local:
; %bb.0:
	v_and_b32_e32 v0, 63, v0
	;;#ASMSTART
	; Branch (34)
	;;#ASMEND
	v_cmp_lt_u32_e32 vcc, 31, v0
	s_and_saveexec_b64 s[0:1], vcc
	s_xor_b64 s[4:5], exec, s[0:1]
	s_cbranch_execz BB0_46
; %bb.1:
	;;#ASMSTART
	; Branch (42)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 47, v0
	s_and_saveexec_b64 s[2:3], s[0:1]
	s_xor_b64 s[6:7], exec, s[2:3]
	s_cbranch_execz BB0_15
; %bb.2:
	;;#ASMSTART
	; Branch (44)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[2:3], 55, v0
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[8:9], exec, s[8:9]
	s_cbranch_execz BB0_5
; %bb.3:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s10, 4
BB0_4:                                  ; =>This Inner Loop Header: Depth=1
	s_add_i32 s10, s10, -1
	s_cmp_lg_u32 s10, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_4
BB0_5:                                  ; %Flow1119
	s_or_saveexec_b64 s[8:9], s[8:9]
	s_xor_b64 exec, exec, s[8:9]
	s_cbranch_execz BB0_8
; %bb.6:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s10, 1
BB0_7:                                  ; =>This Inner Loop Header: Depth=1
	s_add_i32 s10, s10, -1
	s_cmp_lg_u32 s10, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_7
BB0_8:                                  ; %Flow1120
	s_or_b64 exec, exec, s[8:9]
	;;#ASMSTART
	; Branch (45)
	;;#ASMEND
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[2:3], exec, s[8:9]
	s_cbranch_execz BB0_11
; %bb.9:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s8, 4
BB0_10:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_lg_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_10
BB0_11:                                 ; %Flow1114
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_14
; %bb.12:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_13:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_13
BB0_14:                                 ; %Flow1115
	s_or_b64 exec, exec, s[2:3]
BB0_15:                                 ; %Flow1126
	s_or_saveexec_b64 s[6:7], s[6:7]
	s_xor_b64 exec, exec, s[6:7]
	s_cbranch_execz BB0_23
; %bb.16:
	;;#ASMSTART
	; Branch (43)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[2:3], 39, v0
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[2:3], exec, s[8:9]
	s_cbranch_execz BB0_19
; %bb.17:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s8, 4
BB0_18:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_18
BB0_19:                                 ; %Flow1124
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_22
; %bb.20:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_21:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_21
BB0_22:                                 ; %Flow1125
	s_or_b64 exec, exec, s[2:3]
BB0_23:                                 ; %.loopexit466
	s_or_b64 exec, exec, s[6:7]
	;;#ASMSTART
	; Branch (46)
	;;#ASMEND
	s_and_saveexec_b64 s[2:3], s[0:1]
	s_xor_b64 s[2:3], exec, s[2:3]
	s_cbranch_execz BB0_37
; %bb.24:
	;;#ASMSTART
	; Branch (48)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 55, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[6:7], exec, s[6:7]
	s_cbranch_execz BB0_27
; %bb.25:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_26:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_lg_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_26
BB0_27:                                 ; %Flow1101
	s_or_saveexec_b64 s[6:7], s[6:7]
	s_xor_b64 exec, exec, s[6:7]
	s_cbranch_execz BB0_30
; %bb.28:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s8, 1
BB0_29:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_lg_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_29
BB0_30:                                 ; %Flow1102
	s_or_b64 exec, exec, s[6:7]
	;;#ASMSTART
	; Branch (49)
	;;#ASMEND
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_33
; %bb.31:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s6, 4
BB0_32:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_32
BB0_33:                                 ; %Flow1096
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_36
; %bb.34:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_35:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_35
BB0_36:                                 ; %Flow1097
	s_or_b64 exec, exec, s[0:1]
BB0_37:                                 ; %Flow1109
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_45
; %bb.38:
	;;#ASMSTART
	; Branch (47)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 39, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_41
; %bb.39:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s6, 4
BB0_40:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_40
BB0_41:                                 ; %Flow1106
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_44
; %bb.42:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s6, 3
BB0_43:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_43
BB0_44:                                 ; %Flow1107
	s_or_b64 exec, exec, s[0:1]
BB0_45:                                 ; %Flow1110
	s_or_b64 exec, exec, s[2:3]
BB0_46:                                 ; %Flow1158
	s_or_saveexec_b64 s[4:5], s[4:5]
	s_xor_b64 exec, exec, s[4:5]
	s_cbranch_execz BB0_86
; %bb.47:
	;;#ASMSTART
	; Branch (35)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 15, v0
	s_and_saveexec_b64 s[2:3], s[0:1]
	s_xor_b64 s[6:7], exec, s[2:3]
	s_cbranch_execz BB0_61
; %bb.48:
	;;#ASMSTART
	; Branch (37)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[2:3], 23, v0
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[8:9], exec, s[8:9]
	s_cbranch_execz BB0_51
; %bb.49:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s10, 3
BB0_50:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s10, s10, -1
	s_cmp_lg_u32 s10, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_50
BB0_51:                                 ; %Flow1150
	s_or_saveexec_b64 s[8:9], s[8:9]
	s_xor_b64 exec, exec, s[8:9]
	s_cbranch_execz BB0_54
; %bb.52:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s10, 4
BB0_53:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s10, s10, -1
	s_cmp_eq_u32 s10, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_53
BB0_54:                                 ; %Flow1151
	s_or_b64 exec, exec, s[8:9]
	;;#ASMSTART
	; Branch (38)
	;;#ASMEND
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[2:3], exec, s[8:9]
	s_cbranch_execz BB0_57
; %bb.55:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s8, 1
BB0_56:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_56
BB0_57:                                 ; %Flow1146
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_60
; %bb.58:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s8, 4
BB0_59:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_59
BB0_60:                                 ; %Flow1147
	s_or_b64 exec, exec, s[2:3]
BB0_61:                                 ; %Flow1157
	s_or_saveexec_b64 s[6:7], s[6:7]
	s_xor_b64 exec, exec, s[6:7]
	s_cbranch_execz BB0_69
; %bb.62:
	;;#ASMSTART
	; Branch (36)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[2:3], 7, v0
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[2:3], exec, s[8:9]
	s_cbranch_execz BB0_65
; %bb.63:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_64:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_64
BB0_65:                                 ; %Flow1155
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_68
; %bb.66:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s8, 4
BB0_67:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_67
BB0_68:                                 ; %Flow1156
	s_or_b64 exec, exec, s[2:3]
BB0_69:                                 ; %.loopexit454
	s_or_b64 exec, exec, s[6:7]
	;;#ASMSTART
	; Branch (39)
	;;#ASMEND
	s_and_saveexec_b64 s[2:3], s[0:1]
	s_xor_b64 s[2:3], exec, s[2:3]
	s_cbranch_execz BB0_77
; %bb.70:
	;;#ASMSTART
	; Branch (41)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 23, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_73
; %bb.71:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_72:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_72
BB0_73:                                 ; %Flow1131
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_76
; %bb.74:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s6, 4
BB0_75:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_75
BB0_76:                                 ; %Flow1132
	s_or_b64 exec, exec, s[0:1]
BB0_77:                                 ; %Flow1140
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_85
; %bb.78:
	;;#ASMSTART
	; Branch (40)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 7, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_81
; %bb.79:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_80:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_80
BB0_81:                                 ; %Flow1137
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_84
; %bb.82:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s6, 4
BB0_83:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_83
BB0_84:                                 ; %Flow1138
	s_or_b64 exec, exec, s[0:1]
BB0_85:                                 ; %Flow1141
	s_or_b64 exec, exec, s[2:3]
BB0_86:                                 ; %Flow1159
	s_or_b64 exec, exec, s[4:5]
	;;#ASMSTART
	; Branch (50)
	;;#ASMEND
	s_and_saveexec_b64 s[0:1], vcc
	s_xor_b64 s[2:3], exec, s[0:1]
	s_cbranch_execz BB0_110
; %bb.87:
	;;#ASMSTART
	; Branch (55)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 47, v0
	s_and_saveexec_b64 s[4:5], s[0:1]
	s_xor_b64 s[4:5], exec, s[4:5]
	s_cbranch_execz BB0_95
; %bb.88:
	;;#ASMSTART
	; Branch (58)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 55, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_91
; %bb.89:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s6, 3
BB0_90:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_90
BB0_91:                                 ; %Flow1056
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_94
; %bb.92:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s6, 4
BB0_93:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_93
BB0_94:                                 ; %Flow1057
	s_or_b64 exec, exec, s[0:1]
BB0_95:                                 ; %Flow1069
	s_or_saveexec_b64 s[4:5], s[4:5]
	s_xor_b64 exec, exec, s[4:5]
	s_cbranch_execz BB0_109
; %bb.96:
	;;#ASMSTART
	; Branch (56)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 39, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[6:7], exec, s[6:7]
	s_cbranch_execz BB0_99
; %bb.97:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s8, 1
BB0_98:                                 ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_98
BB0_99:                                 ; %Flow1066
	s_or_saveexec_b64 s[6:7], s[6:7]
	s_xor_b64 exec, exec, s[6:7]
	s_cbranch_execz BB0_102
; %bb.100:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_101:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_101
BB0_102:                                ; %Flow1067
	s_or_b64 exec, exec, s[6:7]
	;;#ASMSTART
	; Branch (57)
	;;#ASMEND
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_105
; %bb.103:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s6, 3
BB0_104:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_104
BB0_105:                                ; %Flow1061
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_108
; %bb.106:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s6, 4
BB0_107:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_107
BB0_108:                                ; %Flow1062
	s_or_b64 exec, exec, s[0:1]
BB0_109:                                ; %Flow1070
	s_or_b64 exec, exec, s[4:5]
BB0_110:                                ; %Flow1091
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_134
; %bb.111:
	;;#ASMSTART
	; Branch (51)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 15, v0
	s_and_saveexec_b64 s[4:5], s[0:1]
	s_xor_b64 s[4:5], exec, s[4:5]
	s_cbranch_execz BB0_119
; %bb.112:
	;;#ASMSTART
	; Branch (54)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 23, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_115
; %bb.113:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_114:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_114
BB0_115:                                ; %Flow1075
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_118
; %bb.116:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s6, 3
BB0_117:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_117
BB0_118:                                ; %Flow1076
	s_or_b64 exec, exec, s[0:1]
BB0_119:                                ; %Flow1089
	s_or_saveexec_b64 s[4:5], s[4:5]
	s_xor_b64 exec, exec, s[4:5]
	s_cbranch_execz BB0_133
; %bb.120:
	;;#ASMSTART
	; Branch (52)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 7, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[6:7], exec, s[6:7]
	s_cbranch_execz BB0_123
; %bb.121:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s8, 1
BB0_122:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_122
BB0_123:                                ; %Flow1086
	s_or_saveexec_b64 s[6:7], s[6:7]
	s_xor_b64 exec, exec, s[6:7]
	s_cbranch_execz BB0_126
; %bb.124:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_125:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_125
BB0_126:                                ; %Flow1087
	s_or_b64 exec, exec, s[6:7]
	;;#ASMSTART
	; Branch (53)
	;;#ASMEND
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_129
; %bb.127:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_128:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_128
BB0_129:                                ; %Flow1081
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_132
; %bb.130:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s6, 4
BB0_131:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_131
BB0_132:                                ; %Flow1082
	s_or_b64 exec, exec, s[0:1]
BB0_133:                                ; %Flow1090
	s_or_b64 exec, exec, s[4:5]
BB0_134:                                ; %.loopexit438
	s_or_b64 exec, exec, s[2:3]
	;;#ASMSTART
	; Branch (59)
	;;#ASMEND
	s_and_saveexec_b64 s[0:1], vcc
	s_xor_b64 s[4:5], exec, s[0:1]
	s_cbranch_execz BB0_186
; %bb.135:
	;;#ASMSTART
	; Branch (66)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 47, v0
	s_and_saveexec_b64 s[2:3], s[0:1]
	s_xor_b64 s[6:7], exec, s[2:3]
	s_cbranch_execz BB0_143
; %bb.136:
	;;#ASMSTART
	; Branch (69)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[2:3], 55, v0
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[2:3], exec, s[8:9]
	s_cbranch_execz BB0_139
; %bb.137:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s8, 4
BB0_138:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_lg_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_138
BB0_139:                                ; %Flow1010
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_142
; %bb.140:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_141:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_141
BB0_142:                                ; %Flow1011
	s_or_b64 exec, exec, s[2:3]
BB0_143:                                ; %Flow1023
	s_or_saveexec_b64 s[6:7], s[6:7]
	s_xor_b64 exec, exec, s[6:7]
	s_cbranch_execz BB0_157
; %bb.144:
	;;#ASMSTART
	; Branch (67)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[2:3], 39, v0
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[8:9], exec, s[8:9]
	s_cbranch_execz BB0_147
; %bb.145:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s10, 1
BB0_146:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s10, s10, -1
	s_cmp_eq_u32 s10, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_146
BB0_147:                                ; %Flow1021
	s_or_saveexec_b64 s[8:9], s[8:9]
	s_xor_b64 exec, exec, s[8:9]
	s_cbranch_execz BB0_150
; %bb.148:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s10, 3
BB0_149:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s10, s10, -1
	s_cmp_eq_u32 s10, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_149
BB0_150:                                ; %Flow1022
	s_or_b64 exec, exec, s[8:9]
	;;#ASMSTART
	; Branch (68)
	;;#ASMEND
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[2:3], exec, s[8:9]
	s_cbranch_execz BB0_153
; %bb.151:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s8, 1
BB0_152:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_lg_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_152
BB0_153:                                ; %Flow1016
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_156
; %bb.154:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_155:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_155
BB0_156:                                ; %Flow1017
	s_or_b64 exec, exec, s[2:3]
BB0_157:                                ; %Flow1024
	s_or_b64 exec, exec, s[6:7]
	;;#ASMSTART
	; Branch (70)
	;;#ASMEND
	s_and_saveexec_b64 s[2:3], s[0:1]
	s_xor_b64 s[2:3], exec, s[2:3]
	s_cbranch_execz BB0_171
; %bb.158:
	;;#ASMSTART
	; Branch (73)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 55, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[6:7], exec, s[6:7]
	s_cbranch_execz BB0_161
; %bb.159:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_160:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_lg_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_160
BB0_161:                                ; %Flow992
	s_or_saveexec_b64 s[6:7], s[6:7]
	s_xor_b64 exec, exec, s[6:7]
	s_cbranch_execz BB0_164
; %bb.162:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s8, 4
BB0_163:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_163
BB0_164:                                ; %Flow993
	s_or_b64 exec, exec, s[6:7]
	;;#ASMSTART
	; Branch (74)
	;;#ASMEND
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_167
; %bb.165:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s6, 4
BB0_166:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_166
BB0_167:                                ; %Flow988
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_170
; %bb.168:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_169:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_169
BB0_170:                                ; %Flow989
	s_or_b64 exec, exec, s[0:1]
BB0_171:                                ; %Flow1005
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_185
; %bb.172:
	;;#ASMSTART
	; Branch (71)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 39, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[6:7], exec, s[6:7]
	s_cbranch_execz BB0_175
; %bb.173:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_174:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_lg_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_174
BB0_175:                                ; %Flow1002
	s_or_saveexec_b64 s[6:7], s[6:7]
	s_xor_b64 exec, exec, s[6:7]
	s_cbranch_execz BB0_178
; %bb.176:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s8, 1
BB0_177:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_lg_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_177
BB0_178:                                ; %Flow1003
	s_or_b64 exec, exec, s[6:7]
	;;#ASMSTART
	; Branch (72)
	;;#ASMEND
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_181
; %bb.179:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s6, 3
BB0_180:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_180
BB0_181:                                ; %Flow997
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_184
; %bb.182:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s6, 4
BB0_183:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_183
BB0_184:                                ; %Flow998
	s_or_b64 exec, exec, s[0:1]
BB0_185:                                ; %Flow1006
	s_or_b64 exec, exec, s[2:3]
BB0_186:                                ; %Flow1051
	s_or_saveexec_b64 s[4:5], s[4:5]
	s_xor_b64 exec, exec, s[4:5]
	s_cbranch_execz BB0_220
; %bb.187:
	;;#ASMSTART
	; Branch (60)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 15, v0
	s_and_saveexec_b64 s[2:3], s[0:1]
	s_xor_b64 s[6:7], exec, s[2:3]
	s_cbranch_execz BB0_195
; %bb.188:
	;;#ASMSTART
	; Branch (62)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[2:3], 23, v0
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[2:3], exec, s[8:9]
	s_cbranch_execz BB0_191
; %bb.189:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_190:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_lg_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_190
BB0_191:                                ; %Flow1043
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_194
; %bb.192:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s8, 4
BB0_193:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_193
BB0_194:                                ; %Flow1044
	s_or_b64 exec, exec, s[2:3]
BB0_195:                                ; %Flow1050
	s_or_saveexec_b64 s[6:7], s[6:7]
	s_xor_b64 exec, exec, s[6:7]
	s_cbranch_execz BB0_203
; %bb.196:
	;;#ASMSTART
	; Branch (61)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[2:3], 7, v0
	s_and_saveexec_b64 s[8:9], s[2:3]
	s_xor_b64 s[2:3], exec, s[8:9]
	s_cbranch_execz BB0_199
; %bb.197:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s8, 3
BB0_198:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_198
BB0_199:                                ; %Flow1048
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_202
; %bb.200:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s8, 4
BB0_201:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s8, s8, -1
	s_cmp_eq_u32 s8, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_201
BB0_202:                                ; %Flow1049
	s_or_b64 exec, exec, s[2:3]
BB0_203:                                ; %.loopexit420
	s_or_b64 exec, exec, s[6:7]
	;;#ASMSTART
	; Branch (63)
	;;#ASMEND
	s_and_saveexec_b64 s[2:3], s[0:1]
	s_xor_b64 s[2:3], exec, s[2:3]
	s_cbranch_execz BB0_211
; %bb.204:
	;;#ASMSTART
	; Branch (65)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 23, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_207
; %bb.205:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_206:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_206
BB0_207:                                ; %Flow1029
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_210
; %bb.208:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s6, 3
BB0_209:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_209
BB0_210:                                ; %Flow1030
	s_or_b64 exec, exec, s[0:1]
BB0_211:                                ; %Flow1038
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_219
; %bb.212:
	;;#ASMSTART
	; Branch (64)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 7, v0
	s_and_saveexec_b64 s[6:7], s[0:1]
	s_xor_b64 s[0:1], exec, s[6:7]
	s_cbranch_execz BB0_215
; %bb.213:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_214:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_214
BB0_215:                                ; %Flow1035
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_218
; %bb.216:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s6, 4
BB0_217:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_217
BB0_218:                                ; %Flow1036
	s_or_b64 exec, exec, s[0:1]
BB0_219:                                ; %Flow1039
	s_or_b64 exec, exec, s[2:3]
BB0_220:                                ; %Flow1052
	s_or_b64 exec, exec, s[4:5]
	;;#ASMSTART
	; Branch (75)
	;;#ASMEND
	s_and_saveexec_b64 s[0:1], vcc
	s_xor_b64 s[0:1], exec, s[0:1]
	s_cbranch_execz BB0_238
; %bb.221:
	;;#ASMSTART
	; Branch (83)
	;;#ASMEND
	v_cmp_lt_u32_e32 vcc, 47, v0
	s_and_saveexec_b64 s[2:3], vcc
	s_xor_b64 s[2:3], exec, s[2:3]
	s_cbranch_execz BB0_229
; %bb.222:
	;;#ASMSTART
	; Branch (85)
	;;#ASMEND
	v_cmp_lt_u32_e32 vcc, 55, v0
	s_and_saveexec_b64 s[4:5], vcc
	s_xor_b64 s[4:5], exec, s[4:5]
	s_cbranch_execz BB0_225
; %bb.223:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s6, 3
BB0_224:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_224
BB0_225:                                ; %Flow937
	s_or_saveexec_b64 s[4:5], s[4:5]
	s_xor_b64 exec, exec, s[4:5]
	s_cbranch_execz BB0_228
; %bb.226:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_227:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_227
BB0_228:                                ; %Flow938
	s_or_b64 exec, exec, s[4:5]
BB0_229:                                ; %Flow946
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_237
; %bb.230:
	;;#ASMSTART
	; Branch (84)
	;;#ASMEND
	v_cmp_lt_u32_e32 vcc, 39, v0
	s_and_saveexec_b64 s[4:5], vcc
	s_xor_b64 s[4:5], exec, s[4:5]
	s_cbranch_execz BB0_233
; %bb.231:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s6, 3
BB0_232:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_eq_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_232
BB0_233:                                ; %Flow943
	s_or_saveexec_b64 s[4:5], s[4:5]
	s_xor_b64 exec, exec, s[4:5]
	s_cbranch_execz BB0_236
; %bb.234:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_235:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_235
BB0_236:                                ; %Flow944
	s_or_b64 exec, exec, s[4:5]
BB0_237:                                ; %Flow947
	s_or_b64 exec, exec, s[2:3]
BB0_238:                                ; %Flow982
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_276
; %bb.239:
	;;#ASMSTART
	; Branch (76)
	;;#ASMEND
	v_cmp_lt_u32_e32 vcc, 15, v0
	s_and_saveexec_b64 s[0:1], vcc
	s_xor_b64 s[2:3], exec, s[0:1]
	s_cbranch_execz BB0_247
; %bb.240:
	;;#ASMSTART
	; Branch (79)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 23, v0
	s_and_saveexec_b64 s[4:5], s[0:1]
	s_xor_b64 s[0:1], exec, s[4:5]
	s_cbranch_execz BB0_243
; %bb.241:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s4, 4
BB0_242:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s4, s4, -1
	s_cmp_lg_u32 s4, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_242
BB0_243:                                ; %Flow966
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_246
; %bb.244:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s4, 1
BB0_245:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s4, s4, -1
	s_cmp_lg_u32 s4, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_245
BB0_246:                                ; %Flow967
	s_or_b64 exec, exec, s[0:1]
BB0_247:                                ; %Flow979
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_261
; %bb.248:
	;;#ASMSTART
	; Branch (77)
	;;#ASMEND
	v_cmp_lt_u32_e64 s[0:1], 7, v0
	s_and_saveexec_b64 s[4:5], s[0:1]
	s_xor_b64 s[4:5], exec, s[4:5]
	s_cbranch_execz BB0_251
; %bb.249:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s6, 3
BB0_250:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc1 BB0_250
BB0_251:                                ; %Flow977
	s_or_saveexec_b64 s[4:5], s[4:5]
	s_xor_b64 exec, exec, s[4:5]
	s_cbranch_execz BB0_254
; %bb.252:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s6, 1
BB0_253:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s6, s6, -1
	s_cmp_lg_u32 s6, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_253
BB0_254:                                ; %Flow978
	s_or_b64 exec, exec, s[4:5]
	;;#ASMSTART
	; Branch (78)
	;;#ASMEND
	s_and_saveexec_b64 s[4:5], s[0:1]
	s_xor_b64 s[0:1], exec, s[4:5]
	s_cbranch_execz BB0_257
; %bb.255:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s4, 4
BB0_256:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s4, s4, -1
	s_cmp_eq_u32 s4, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_256
BB0_257:                                ; %Flow972
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_260
; %bb.258:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s4, 1
BB0_259:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s4, s4, -1
	s_cmp_lg_u32 s4, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_259
BB0_260:                                ; %Flow973
	s_or_b64 exec, exec, s[0:1]
BB0_261:                                ; %Flow980
	s_or_b64 exec, exec, s[2:3]
	;;#ASMSTART
	; Branch (80)
	;;#ASMEND
	s_and_saveexec_b64 s[0:1], vcc
	s_xor_b64 s[0:1], exec, s[0:1]
	s_cbranch_execz BB0_269
; %bb.262:
	;;#ASMSTART
	; Branch (82)
	;;#ASMEND
	v_cmp_lt_u32_e32 vcc, 23, v0
	s_and_saveexec_b64 s[2:3], vcc
	s_xor_b64 s[2:3], exec, s[2:3]
	s_cbranch_execz BB0_265
; %bb.263:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s4, 3
BB0_264:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s4, s4, -1
	s_cmp_eq_u32 s4, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_264
BB0_265:                                ; %Flow952
	s_or_saveexec_b64 s[2:3], s[2:3]
	s_xor_b64 exec, exec, s[2:3]
	s_cbranch_execz BB0_268
; %bb.266:
	;;#ASMSTART
	; Iterations (2)
	;;#ASMEND
	s_mov_b32 s4, 1
BB0_267:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s4, s4, -1
	s_cmp_lg_u32 s4, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_267
BB0_268:                                ; %Flow953
	s_or_b64 exec, exec, s[2:3]
BB0_269:                                ; %Flow960
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_276
; %bb.270:
	;;#ASMSTART
	; Branch (81)
	;;#ASMEND
	v_cmp_lt_u32_e32 vcc, 7, v0
	s_and_saveexec_b64 s[0:1], vcc
	s_xor_b64 s[0:1], exec, s[0:1]
	s_cbranch_execz BB0_273
; %bb.271:
	;;#ASMSTART
	; Iterations (4)
	;;#ASMEND
	s_mov_b32 s2, 4
BB0_272:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s2, s2, -1
	s_cmp_eq_u32 s2, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_272
BB0_273:                                ; %Flow957
	s_or_saveexec_b64 s[0:1], s[0:1]
	s_xor_b64 exec, exec, s[0:1]
	s_cbranch_execz BB0_276
; %bb.274:
	;;#ASMSTART
	; Iterations (3)
	;;#ASMEND
	s_mov_b32 s0, 3
BB0_275:                                ; =>This Inner Loop Header: Depth=1
	s_add_i32 s0, s0, -1
	s_cmp_eq_u32 s0, 0
	;;#ASMSTART
	v_and_b32_e32 v1, 1, v1
	;;#ASMEND
	s_cbranch_scc0 BB0_275
BB0_276:                                ; %.loopexit
	s_endpgm
	.section	.rodata,#alloc
	.p2align	6
	.amdhsa_kernel _Z9syntheticm
		.amdhsa_group_segment_fixed_size 0
		.amdhsa_private_segment_fixed_size 0
		.amdhsa_user_sgpr_private_segment_buffer 1
		.amdhsa_user_sgpr_dispatch_ptr 0
		.amdhsa_user_sgpr_queue_ptr 0
		.amdhsa_user_sgpr_kernarg_segment_ptr 1
		.amdhsa_user_sgpr_dispatch_id 0
		.amdhsa_user_sgpr_flat_scratch_init 0
		.amdhsa_user_sgpr_private_segment_size 0
		.amdhsa_system_sgpr_private_segment_wavefront_offset 0
		.amdhsa_system_sgpr_workgroup_id_x 1
		.amdhsa_system_sgpr_workgroup_id_y 0
		.amdhsa_system_sgpr_workgroup_id_z 0
		.amdhsa_system_sgpr_workgroup_info 0
		.amdhsa_system_vgpr_workitem_id 0
		.amdhsa_next_free_vgpr 2
		.amdhsa_next_free_sgpr 11
		.amdhsa_reserve_flat_scratch 0
		.amdhsa_float_round_mode_32 0
		.amdhsa_float_round_mode_16_64 0
		.amdhsa_float_denorm_mode_32 3
		.amdhsa_float_denorm_mode_16_64 3
		.amdhsa_dx10_clamp 1
		.amdhsa_ieee_mode 1
		.amdhsa_exception_fp_ieee_invalid_op 0
		.amdhsa_exception_fp_denorm_src 0
		.amdhsa_exception_fp_ieee_div_zero 0
		.amdhsa_exception_fp_ieee_overflow 0
		.amdhsa_exception_fp_ieee_underflow 0
		.amdhsa_exception_fp_ieee_inexact 0
		.amdhsa_exception_int_div_zero 0
	.end_amdhsa_kernel
	.text
.Lfunc_end0:
	.size	_Z9syntheticm, .Lfunc_end0-_Z9syntheticm
                                        ; -- End function
	.section	.AMDGPU.csdata
; Kernel info:
; codeLenInByte = 3384
; NumSgprs: 15
; NumVgprs: 1
; ScratchSize: 0
; MemoryBound: 0
; FloatMode: 240
; IeeeMode: 1
; LDSByteSize: 0 bytes/workgroup (compile time only)
; SGPRBlocks: 1
; VGPRBlocks: 0
; NumSGPRsForWavesPerEU: 15
; NumVGPRsForWavesPerEU: 2
; Occupancy: 10
; WaveLimiterHint : 0
; COMPUTE_PGM_RSRC2:USER_SGPR: 6
; COMPUTE_PGM_RSRC2:TRAP_HANDLER: 0
; COMPUTE_PGM_RSRC2:TGID_X_EN: 1
; COMPUTE_PGM_RSRC2:TGID_Y_EN: 0
; COMPUTE_PGM_RSRC2:TGID_Z_EN: 0
; COMPUTE_PGM_RSRC2:TIDIG_COMP_CNT: 0
	.ident	"clang version 12.0.0 (/src/external/llvm-project/clang 1100ebe275a9dcc79a9abbda902b6f10738f2f5d)"
	.section	".note.GNU-stack"
	.addrsig
	.amdgpu_metadata
---
amdhsa.kernels:
  - .args:
      - .offset:         0
        .size:           8
        .value_kind:     by_value
      - .offset:         8
        .size:           8
        .value_kind:     hidden_global_offset_x
      - .offset:         16
        .size:           8
        .value_kind:     hidden_global_offset_y
      - .offset:         24
        .size:           8
        .value_kind:     hidden_global_offset_z
      - .address_space:  global
        .offset:         32
        .size:           8
        .value_kind:     hidden_none
      - .address_space:  global
        .offset:         40
        .size:           8
        .value_kind:     hidden_none
      - .address_space:  global
        .offset:         48
        .size:           8
        .value_kind:     hidden_none
      - .address_space:  global
        .offset:         56
        .size:           8
        .value_kind:     hidden_multigrid_sync_arg
    .group_segment_fixed_size: 0
    .kernarg_segment_align: 8
    .kernarg_segment_size: 64
    .language:       OpenCL C
    .language_version:
      - 2
      - 0
    .max_flat_workgroup_size: 256
    .name:           _Z9syntheticm
    .private_segment_fixed_size: 0
    .sgpr_count:     15
    .sgpr_spill_count: 0
    .symbol:         _Z9syntheticm.kd
    .vgpr_count:     2
    .vgpr_spill_count: 0
    .wavefront_size: 64
amdhsa.version:
  - 1
  - 0
...

	.end_amdgpu_metadata
